# docker-compose.yml

services:
  service-a:
    build:
      context: ./services/service-a
      dockerfile: Dockerfile
    image: ai-adaptive-sandbox-service-a
    container_name: service-a
    environment:
      SERVICE_B_URL: http://toxiproxy:8666
      OTEL_SERVICE_NAME: service-a
      OTEL_TRACES_EXPORTER: otlp
      OTEL_TRACES_SAMPLER: always_on
      OTEL_PROPAGATORS: tracecontext,baggage
      OTEL_EXPORTER_OTLP_PROTOCOL: http/protobuf
      OTEL_EXPORTER_OTLP_ENDPOINT: http://otel-collector:4318
      OTEL_EXPORTER_OTLP_TRACES_ENDPOINT: http://otel-collector:4318/v1/traces
      OTEL_LOG_LEVEL: debug
    ports:
      - "8081:8080"
    depends_on: [otel-collector]

  service-b:
    build:
      context: ./services/service-b
      dockerfile: Dockerfile
    image: ai-adaptive-sandbox-service-b
    container_name: service-b
    environment:
      SERVICE_C_URL: http://toxiproxy:8667
      OTEL_SERVICE_NAME: service-b
      OTEL_TRACES_EXPORTER: otlp
      OTEL_TRACES_SAMPLER: always_on
      OTEL_PROPAGATORS: tracecontext,baggage
      OTEL_EXPORTER_OTLP_PROTOCOL: http/protobuf
      OTEL_EXPORTER_OTLP_ENDPOINT: http://otel-collector:4318
      OTEL_EXPORTER_OTLP_TRACES_ENDPOINT: http://otel-collector:4318/v1/traces
      OTEL_LOG_LEVEL: debug
    expose:
      - "8080"
    depends_on: [otel-collector, service-c]

  service-c:
    build:
      context: ./services/service-c
      dockerfile: Dockerfile
    image: ai-adaptive-sandbox-service-c
    container_name: service-c
    environment:
      OTEL_SERVICE_NAME: service-c
      OTEL_TRACES_EXPORTER: otlp
      OTEL_TRACES_SAMPLER: always_on
      OTEL_PROPAGATORS: tracecontext,baggage
      OTEL_EXPORTER_OTLP_PROTOCOL: http/protobuf
      OTEL_EXPORTER_OTLP_ENDPOINT: http://otel-collector:4318
      OTEL_EXPORTER_OTLP_TRACES_ENDPOINT: http://otel-collector:4318/v1/traces
      OTEL_LOG_LEVEL: debug
    expose:
      - "8080"
    depends_on: [otel-collector]
  
  ai-predictor:
    build:
      context: ./services/ai-predictor
    image: ai-adaptive-sandbox-ai-predictor
    container_name: ai-predictor
    environment:
      OTEL_SERVICE_NAME: ai-predictor
    ports:
      - "8003:8000"
    depends_on: [otel-collector]



  otel-collector:
    image: otel/opentelemetry-collector:0.103.1
    command: ["--config=/etc/otelcol/config.yaml"]
    volumes:
      - ./observability/otel-collector-config.yaml:/etc/otelcol/config.yaml:ro
      - ./data/captures:/captures
    ports:
      - "4318:4318"   # OTLP http
      - "4317:4317"   # OTLP grpc

  jaeger:
    image: jaegertracing/all-in-one:1.57
    ports:
      - "16686:16686"

  prometheus:
    image: prom/prometheus:v2.55.0
    volumes:
      - ./observability/prometheus.yml:/etc/prometheus/prometheus.yml:ro
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
    ports:
      - "9090:9090"

  grafana:
    image: grafana/grafana:11.0.0
    environment:
      - GF_AUTH_ANONYMOUS_ENABLED=true
      - GF_AUTH_ANONYMOUS_ORG_ROLE=Admin
      - GF_SECURITY_ALLOW_EMBEDDING=true
    volumes:
      # Phase 0.1.5 provisioning
      - ./observability/grafana-datasources.yml:/etc/grafana/provisioning/datasources/datasources.yml
      - ./observability/grafana-dashboards/dashboards.yml:/etc/grafana/provisioning/dashboards/dashboards.yml
      - ./observability/grafana-dashboards:/var/lib/grafana/dashboards
    ports:
      - "3000:3000"

  # Phase 0.2 failure injection
  toxiproxy:
    image: shopify/toxiproxy
    container_name: toxiproxy
    ports:
      - "8474:8474"   # admin API
      - "8666:8666"   # A→B proxy
      - "8667:8667"   # B→C proxy
    healthcheck:
      test: ["CMD", "wget", "--spider", "-q", "http://localhost:8474/version"]
      interval: 5s
      timeout: 3s
      retries: 5
  toxiproxy-init:
    image: curlimages/curl:latest
    depends_on:
      toxiproxy:
        condition: service_healthy
    command: >
      sh -c "
      echo 'Creating Toxiproxy proxies...' &&
      curl -X POST http://toxiproxy:8474/proxies 
        -H 'Content-Type: application/json' 
        -d '{\"name\":\"a_to_b\",\"listen\":\"0.0.0.0:8666\",\"upstream\":\"service-b:8080\",\"enabled\":true}' &&
      curl -X POST http://toxiproxy:8474/proxies 
        -H 'Content-Type: application/json' 
        -d '{\"name\":\"b_to_c\",\"listen\":\"0.0.0.0:8667\",\"upstream\":\"service-c:8080\",\"enabled\":true}' &&
      echo '✅ Proxies created successfully!'
      "
    restart: "no"

  # Phase 0.1.5 mock Slack webhook
  mock-slack:
    image: mendhak/http-https-echo:latest
    environment:
      - HTTP_PORT=8080
    ports:
      - "5000:8080"
